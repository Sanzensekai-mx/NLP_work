{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_gensim_voz_kod.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUp6AqBxMgA8"
      },
      "source": [
        "Подключение Google Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mlnTB-LLSyE",
        "outputId": "64f2e608-d0c9-4cd4-fd11-3e58afa1f45c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHXr0heCN6JL"
      },
      "source": [
        "Подключение необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmvHi2U_MZEp"
      },
      "source": [
        "import dataset\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.corpora import Dictionary\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import os\n",
        "import pymorphy2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwbkz_QHRLIh"
      },
      "source": [
        "Подготовка текста Воздушного Кодекса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFS6j2rkMusT"
      },
      "source": [
        "article_text = ''\n",
        "with open(os.path.join('/content/drive/MyDrive', 'NLP_work', 'example', 'txt', 'voz_kod', 'voz_kod', 'voz_kod.txt'), 'r', encoding='utf-8') as r:\n",
        "    for line in r:\n",
        "        article_text += line\n",
        "processed_article = article_text.lower()\n",
        "processed_article = re.sub('[^а-яА-Я]', ' ', processed_article)\n",
        "processed_article = re.sub(r'\\s+', ' ', processed_article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drkrZ0VkRXNB"
      },
      "source": [
        "Подкготовка набора данных из слов ВК"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_oHn2neM2vC"
      },
      "source": [
        "# all_sentences = nltk.sent_tokenize(processed_article)\n",
        "# all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
        "all_words = nltk.word_tokenize(processed_article)\n",
        "# print(len(all_words[0]))\n",
        "# print(len(alll_words))\n",
        "print(all_words)\n",
        "# print('=======================================================================')\n",
        "# print(alll_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veIP5d6XM6PO"
      },
      "source": [
        "v1 = word2vec.wv[\"меры\"]\n",
        "v2 = word2vec.wv['экипаж']\n",
        "print(v1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KHqtNt7NARj"
      },
      "source": [
        "sim_words = word2vec.wv.most_similar(\"правила\")\n",
        "print(sim_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkHVmvBUNCXy"
      },
      "source": [
        "print(word2vec.wv.similar_by_vector(v1 + v2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8th318WNGNI"
      },
      "source": [
        "word2vec.train([[\"пилот\", \"пилотесса\", \"мужчина\", \"женщина\"]], total_examples=4, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHhPo4C7NIs5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# print(word2vec.wv[\"кодекс\"])\n",
        "vec_voc = {k: word2vec.wv[k] for k in vocabulary.keys()}\n",
        "print(len(vec_voc.values()), len(vec_voc.keys()))\n",
        "# print(list(vec_voc.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6_wpr0zNLKa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "def tsne_scatterplot(model, word, list_names):\n",
        "    \"\"\"Plot in seaborn the results from the t-SNE dimensionality reduction \n",
        "    algorithm of the vectors of a query word,\n",
        "    its list of most similar words, and a list of words.\"\"\"\n",
        "    vectors_words = [model.wv.get_vector(word)]\n",
        "    word_labels = [word]\n",
        "    color_list = ['red']\n",
        "    close_words = model.wv.most_similar(word)\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model.wv.get_vector(wrd_score[0])\n",
        "        vectors_words.append(wrd_vector)\n",
        "        word_labels.append(wrd_score[0])\n",
        "        color_list.append('blue')\n",
        "    # adds the vector for each of the words from list_names to the array\n",
        "    for wrd in list_names:\n",
        "        wrd_vector = model.wv.get_vector(wrd)\n",
        "        vectors_words.append(wrd_vector)\n",
        "        word_labels.append(wrd)\n",
        "        color_list.append('green')\n",
        "    # t-SNE reduction\n",
        "    Y = (TSNE(n_components=2, random_state=0, perplexity=15, init=\"pca\")\n",
        "        .fit_transform(vectors_words))\n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({\"x\": [x for x in Y[:, 0]],\n",
        "                    \"y\": [y for y in Y[:, 1]],\n",
        "                    \"words\": word_labels,\n",
        "                    \"color\": color_list})\n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                    x=\"x\",\n",
        "                    y=\"y\",\n",
        "                    fit_reg=False,\n",
        "                    marker=\"o\",\n",
        "                    scatter_kws={\"s\": 40,\n",
        "                                \"facecolors\": df[\"color\"]}\n",
        "    )\n",
        "    # Adds annotations one by one with a loop\n",
        "#     for line in range(0, df.shape[0]):\n",
        "#         p1.text(df[\"x\"][line],\n",
        "#                 df[\"y\"][line],\n",
        "#                 \" \" + df[\"words\"][line].title(),\n",
        "#                 horizontalalignment=\"left\",\n",
        "#                 verticalalignment=\"bottom\", size=\"medium\",\n",
        "#                 color=df[\"color\"][line],\n",
        "#                 weight=\"normal\"\n",
        "#         ).set_size(12)\n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "    plt.title('t-SNE visualization for {}'.format(word.title()))\n",
        "\n",
        "def tsne_plot_common(model, list_words):\n",
        "    vectors_words = []\n",
        "    word_labels = []\n",
        "    color_list = []\n",
        "    for wrd in list_words:\n",
        "        wrd_vector = model.wv.get_vector(wrd)\n",
        "        vectors_words.append(wrd_vector)\n",
        "        word_labels.append(wrd)\n",
        "        color_list.append('blue')\n",
        "     # t-SNE reduction\n",
        "    Y = (TSNE(n_components=2, random_state=0, perplexity=15, init=\"pca\")\n",
        "        .fit_transform(vectors_words))\n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({\"x\": [x for x in Y[:, 0]],\n",
        "                    \"y\": [y for y in Y[:, 1]],\n",
        "                    \"words\": word_labels,\n",
        "                    \"color\": color_list})\n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                    x=\"x\",\n",
        "                    y=\"y\",\n",
        "                    fit_reg=False,\n",
        "                    marker=\"o\",\n",
        "                    scatter_kws={\"s\": 40,\n",
        "                                \"facecolors\": df[\"color\"]}\n",
        "    )\n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "    plt.title('t-SNE visualization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldZzqrqqNN2Z"
      },
      "source": [
        "# tsne_scatterplot(word2vec, \"аэродром\", [\"аэропорт\", \"судно\", \"пилот\", \"пассажир\", \"экипаж\", \"федеральный\"])\n",
        "# tsne_scatterplot(word2vec, \"экипаж\", vec_voc.keys())\n",
        "tsne_plot_common(word2vec, vec_voc.keys())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}